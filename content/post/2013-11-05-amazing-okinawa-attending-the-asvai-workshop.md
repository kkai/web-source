---
categories:
- posts
date: 2013-11-05T00:00:00Z
summary: Cool research discussions at a nice location. The workshop was perfect fit
  to my research interests.
title: Amazing Okinawa - Attending the ASVAI Workshop
url: /2013/11/05/amazing-okinawa-attending-the-asvai-workshop/
---

<p class="lead">Cool research discussions at a nice location. The workshop was perfect fit to my research interests.</p>

The [ASVAI workshop](http://www.am.sanken.osaka-u.ac.jp/ASVAI2013/) gave a good overview about several research 
efforts part of and related to the [JST CREST](http://www.jst.go.jp/kisoken/crest/en/research_area/ongoing/areah21-1.html) and the JSPS Core-to-Core Sanken Program. 

[Prof. Yasushi Yagi](http://www.am.sanken.osaka-u.ac.jp/~yagi/)
showed how to infer intention from gait analysis.
Interestingly, he showed research about the relationship
of gaze and gait.

[Dr. Alireza Fathi](http://ai.stanford.edu/~alireza/)
presented cool work about ego centric cameras. He showed
how to estimate gaze using ego centric cameras during
cooking tasks and psychological studies.

[Prof. Hanako Yoshida](http://www.uh.edu/class/psychology/about/people/hanako-yoshida/index.php) explores
social learning in infants (equipping children with mobile
eye trackers ... awesome!), inferring developmental stages
giving more insights in the learning process. 

[Prof. Masahiro Shiomi](http://www.irc.atr.jp/~m-shiomi/)
spoke about his research trying to adapt robot behavior
to fit into social public spaces ( videos about 
people running away from a robot included ;) ).
Currently, they focus on service robots and model their
behavior according to successful human service personnel.

[Prof. Yoichi Sato](http://www.hci.iis.u-tokyo.ac.jp/~ysato/) presented work related to
detecting visual attention. They use visual saliency
on video to train an appearance-based eye tracking.
Really interesting work, I had a chance to talk a bit 
more with [Yusuke Sugano](http://www.hci.iis.u-tokyo.ac.jp/~sugano/), cool research :)

Of course, Koichi also gave an overview about our work.
If you want to read more, checkout the [IEEE Computer article](/papers/pdf/kunze2013activity.pdf).

I'm looking forward to the main conference.
Here's a tag cloud using the abstracts of ACPR and ASVAI papers:

![Tag cloud](/imgs/acpr_wordcloud.png)

We present demonstrations and new results 
of the eye tracking on commodity
tablets/smart phones and a sharing infrastructure for our document annotation for smart phones.

