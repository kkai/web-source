---
categories:
- conference
date: 2013-09-15T00:00:00Z
description: ""
summary: Usually, I'm not such a big fan of conference openings, ...
tagline: great time in Zurich
tags:
- conference
- research
- ubicomp
- iswc
title: Ubicomp ISWC Impressions
url: /2013/09/15/ubicom-iswc-impressions/
---

Usually, I'm not such a big fan of conference openings,
yet Friedemann Mattern provided a great intro giving
an overview about the origins of Pervasive and Ubicom
mentioning all important people and showing nice vintage
pictures from Hans Gellersen, Alois Ferscha,  Marc Langheinrich, Albrecht Schmidt, Kristof Van Laerhoven etc. 

Deeply impressed by the organization, social and general 
talk quality, I was a bit sceptical before the merger
of Pervasive / Ubicom and collocating ISWC, yet it was
completely unfounded. 

We got some great feedback for Kazuma's and Shoya's demos.
They both did a great job introducing their work about:

* [My Reading Life – Towards Utilizing Eyetracking on Unmodified Tablets and Phones](/papers/kunze2013my.pdf)
* [Annotate Me – Supporting Active Reading using Real-Time Document Image Retrieval On Mobile Devices](/papers/kunze2013annotate.pdf)


We got also a lof of interest and feedback
to Andreas Bulling's and my work about recognizing 
document types using only eye gaze.
By the way, below are the talk slides and the abstract of 
the paper.
##ISWC Talk Slides##

<script class="speakerdeck-embed" data-id="a0f70c60fdc20130468e062acf92b5fe" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js">  </script>

##Abstract##
Reading is a ubiquitous activity that many people even per- form in transit, such as while on the bus or while walking. Tracking reading enables us to gain more insights about ex- pertise level and potential knowledge of users – towards a reading log tracking and improve knowledge acquisition. As a first step towards this vision, in this work we investigate whether different document types can be automatically de- tected from visual behaviour recorded using a mobile eye tracker. We present an initial recognition approach that com- bines special purpose eye movement features as well as ma- chine learning for document type detection. We evaluate our approach in a user study with eight participants and five Japanese document types and achieve a recognition perfor- mance of 74% using user-independent training.

Full paper link:
[I know what you are reading – Recognition of Document Types Using Mobile Eye Tracking](/papers/2013Kunze-5.pdf)




